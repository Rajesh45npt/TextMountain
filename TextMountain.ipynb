{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, models, transforms\n",
    "import os\n",
    "import copy\n",
    "from IPython.display import clear_output\n",
    "from torchsummary import summary\n",
    "from tensorboardX import SummaryWriter\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ResNet = models.resnet50(pretrained=True)\n",
    "# for classifier in ResNet.children():\n",
    "#     print(classifier)\n",
    "#     input()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from torchsummary import summary\n",
    "summary(ResNet, (3,224,224))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "with SummaryWriter(\"runs/resnet\",comment=\"Model Resnet\") as w:\n",
    "    w.add_graph(ResNet, torch.zeros(1,3,224,224), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Downloads/y/envs/tm/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.UpsamplingNearest2d is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n",
      "/home/raj/Downloads/y/envs/tm/lib/python3.6/site-packages/ipykernel_launcher.py:90: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "/home/raj/Downloads/y/envs/tm/lib/python3.6/site-packages/ipykernel_launcher.py:91: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "/home/raj/Downloads/y/envs/tm/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.UpsamplingBilinear2d is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n",
      "/home/raj/Downloads/y/envs/tm/lib/python3.6/site-packages/torch/onnx/symbolic.py:131: UserWarning: ONNX export failed on upsample_bilinear2d because align_corners == True not supported\n",
      "  warnings.warn(\"ONNX export failed on \" + op + \" because \" + msg + \" not supported\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
      "             ReLU-81          [-1, 256, 28, 28]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
      "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-89         [-1, 1024, 14, 14]               0\n",
      "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
      "             ReLU-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
      "            ReLU-103          [-1, 256, 14, 14]               0\n",
      "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
      "            ReLU-106          [-1, 256, 14, 14]               0\n",
      "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-109         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
      "            ReLU-113          [-1, 256, 14, 14]               0\n",
      "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
      "            ReLU-116          [-1, 256, 14, 14]               0\n",
      "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-143          [-1, 512, 14, 14]               0\n",
      "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-146            [-1, 512, 7, 7]               0\n",
      "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-151           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-155            [-1, 512, 7, 7]               0\n",
      "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-158            [-1, 512, 7, 7]               0\n",
      "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-161           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-165            [-1, 512, 7, 7]               0\n",
      "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-168            [-1, 512, 7, 7]               0\n",
      "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-171           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-173            [-1, 256, 7, 7]         524,544\n",
      "          Conv2d-174            [-1, 128, 7, 7]         295,040\n",
      "          Conv2d-175            [-1, 128, 7, 7]         147,584\n",
      "UpsamplingNearest2d-176          [-1, 256, 14, 14]               0\n",
      "          Conv2d-177          [-1, 256, 14, 14]         262,400\n",
      "          Conv2d-178          [-1, 128, 14, 14]         295,040\n",
      "          Conv2d-179          [-1, 128, 14, 14]         147,584\n",
      "UpsamplingNearest2d-180          [-1, 256, 28, 28]               0\n",
      "          Conv2d-181          [-1, 256, 28, 28]         131,328\n",
      "          Conv2d-182          [-1, 128, 28, 28]         295,040\n",
      "          Conv2d-183          [-1, 128, 28, 28]         147,584\n",
      "UpsamplingNearest2d-184          [-1, 256, 56, 56]               0\n",
      "          Conv2d-185          [-1, 256, 56, 56]          65,792\n",
      "          Conv2d-186          [-1, 128, 56, 56]         295,040\n",
      "          Conv2d-187          [-1, 128, 56, 56]         147,584\n",
      "UpsamplingNearest2d-188          [-1, 128, 56, 56]               0\n",
      "UpsamplingNearest2d-189          [-1, 128, 56, 56]               0\n",
      "UpsamplingNearest2d-190          [-1, 128, 56, 56]               0\n",
      "          Conv2d-191          [-1, 512, 54, 54]       2,359,808\n",
      "     BatchNorm2d-192          [-1, 512, 54, 54]           1,024\n",
      "            ReLU-193          [-1, 512, 54, 54]               0\n",
      "          Conv2d-194            [-1, 2, 54, 54]           1,026\n",
      "================================================================\n",
      "Total params: 28,624,450\n",
      "Trainable params: 28,624,450\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 354.25\n",
      "Params size (MB): 109.19\n",
      "Estimated Total Size (MB): 464.02\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        resnet_layers = list(models.resnet50(pretrained=True).children())\n",
    "#         print(resnet_layers)\n",
    "        self.resnet_1 = nn.Sequential(*resnet_layers[:-5])\n",
    "        self.resnet_2 = nn.Sequential(*resnet_layers[-5])\n",
    "        self.resnet_3 = nn.Sequential(*resnet_layers[-4])\n",
    "        self.resnet_4 = nn.Sequential(*resnet_layers[-3])\n",
    "        \n",
    "        self.conv11_resnet_1 = nn.Conv2d(in_channels=256,out_channels=256, kernel_size=(1,1), stride=(1,1))\n",
    "        self.conv11_resnet_2 = nn.Conv2d(in_channels=512,out_channels=256, kernel_size=(1,1), stride=(1,1))\n",
    "        self.conv11_resnet_3 = nn.Conv2d(in_channels=1024,out_channels=256, kernel_size=(1,1), stride=(1,1))\n",
    "        self.conv11_resnet_4 = nn.Conv2d(in_channels=2048,out_channels=256, kernel_size=(1,1), stride=(1,1))\n",
    "        \n",
    "        self.scaling_1 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.scaling_2 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.scaling_3 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        \n",
    "        self.conv33_td1_1 = nn.Conv2d(in_channels=256, out_channels=128,kernel_size=(3,3),stride=(1,1), padding=(1,1))\n",
    "        self.conv33_td1_2 = nn.Conv2d(in_channels=128, out_channels=128,kernel_size=(3,3),stride=(1,1), padding=(1,1))\n",
    "        self.conv33_td2_1 = nn.Conv2d(in_channels=256, out_channels=128,kernel_size=(3,3),stride=(1,1), padding=(1,1))\n",
    "        self.conv33_td2_2 = nn.Conv2d(in_channels=128, out_channels=128,kernel_size=(3,3),stride=(1,1), padding=(1,1))\n",
    "        self.conv33_td3_1 = nn.Conv2d(in_channels=256, out_channels=128,kernel_size=(3,3),stride=(1,1), padding=(1,1))\n",
    "        self.conv33_td3_2 = nn.Conv2d(in_channels=128, out_channels=128,kernel_size=(3,3),stride=(1,1), padding=(1,1))\n",
    "        self.conv33_td4_1 = nn.Conv2d(in_channels=256, out_channels=128,kernel_size=(3,3),stride=(1,1), padding=(1,1))\n",
    "        self.conv33_td4_2 = nn.Conv2d(in_channels=128, out_channels=128,kernel_size=(3,3),stride=(1,1), padding=(1,1))\n",
    "        \n",
    "        self.scaling_P1 = nn.UpsamplingNearest2d(scale_factor=8)\n",
    "        self.scaling_P2 = nn.UpsamplingNearest2d(scale_factor=4)\n",
    "        self.scaling_P3 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        \n",
    "        self.conv3_final = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3,3), stride=(1,1))\n",
    "        self.batchnorm_final = nn.BatchNorm2d(512)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.conv1_final = nn.Conv2d(in_channels=512, out_channels=2, kernel_size=(1,1), stride=(1,1))\n",
    "        \n",
    "        \n",
    "#         self.scaling = nn.ConvTranspose2d(in_channels=256, out_channels=256,kernel_size=(2,2), stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_bu1 = self.resnet_1(x)\n",
    "        x_bu2 = self.resnet_2(x_bu1)\n",
    "        x_bu3 = self.resnet_3(x_bu2)\n",
    "        x_bu4 = self.resnet_4(x_bu3)\n",
    "#         print(\"Bottom-up\")\n",
    "#         print(x_bu1.shape)\n",
    "#         print(x_bu2.shape)\n",
    "#         print(x_bu3.shape)\n",
    "#         print(x_bu4.shape)\n",
    "        \n",
    "        \n",
    "        x_td1 = self.conv11_resnet_4(x_bu4)\n",
    "        P_1 = self.conv33_td1_1(x_td1)\n",
    "        P_1 = self.conv33_td1_2(P_1)\n",
    "        \n",
    "        x_td2_1 = self.scaling_1(x_td1)\n",
    "        x_td2_2 = self.conv11_resnet_3(x_bu3)\n",
    "        x_td2 = x_td2_1+x_td2_2\n",
    "        P_2 = self.conv33_td2_1(x_td2)\n",
    "        P_2 = self.conv33_td2_2(P_2)\n",
    "        \n",
    "        x_td3_1 = self.scaling_2(x_td2)\n",
    "        x_td3_2 = self.conv11_resnet_2(x_bu2)\n",
    "        x_td3 = x_td3_1+x_td3_2\n",
    "        P_3 = self.conv33_td3_1(x_td3)\n",
    "        P_3 = self.conv33_td3_2(P_3)\n",
    "        \n",
    "        x_td4_1 = self.scaling_3(x_td3)\n",
    "        x_td4_2 = self.conv11_resnet_1(x_bu1)\n",
    "        x_td4 = x_td4_1+x_td4_2\n",
    "        P_4 = self.conv33_td4_1(x_td4)\n",
    "        P_4 = self.conv33_td4_2(P_4)\n",
    "        \n",
    "        \n",
    "        P_1 = self.scaling_P1(P_1)\n",
    "        P_2 = self.scaling_P2(P_2)\n",
    "        P_3 = self.scaling_P3(P_3)\n",
    "        \n",
    "        P_concat = torch.cat((P_1, P_2, P_3, P_4), dim=1)\n",
    "        F = P_concat\n",
    "#         print(\"P_concat\")\n",
    "#         print(P_concat.shape)\n",
    "        \n",
    "        F = self.conv3_final(F)\n",
    "        F = self.batchnorm_final(F)\n",
    "        F = self.activation(F)\n",
    "        \n",
    "        F = self.conv1_final(F)\n",
    "        F = nn.UpsamplingBilinear2d(size = (int(x.size()[-2]),\n",
    "                                          int(x.size()[-1])))(F)\n",
    "#         F = nn.Softmax2d()(F)\n",
    "#         print(\"Top-down\")\n",
    "#         print(x_td4.shape)\n",
    "#         print(x_td3.shape)\n",
    "#         print(x_td2.shape)\n",
    "#         print(x_td1.shape)\n",
    "        \n",
    "#         print(\"P\")\n",
    "#         print(P_1.shape)\n",
    "#         print(P_2.shape)\n",
    "#         print(P_3.shape)\n",
    "#         print(P_4.shape)\n",
    "#         print(P_concat.shape)\n",
    "        \n",
    "#         print(\"F\")\n",
    "#         print(x.shape)\n",
    "#         print(F.shape)\n",
    "        \n",
    "        \n",
    "        return F\n",
    "with SummaryWriter(\"runs/MyModel\") as w:\n",
    "    w.add_graph(MyModel(),torch.zeros(1,3,224,224), False)\n",
    "summary(MyModel(), (3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 224, 224])\n",
      "tensor(-0.1556, grad_fn=<SelectBackward>) tensor(-0.1465, grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = MyModel()\n",
    "out=model(torch.randn((2,3,224,224)))\n",
    "print(out.shape)\n",
    "print(out[1,0,1,1], out[1,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 224, 224])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossentropy_loss(input_tensor, target=None, weight=None ):\n",
    "    n,c,h,w = input_tensor.size()\n",
    "    \n",
    "    \n",
    "#     target = target.repeat(1,3,1,1)\n",
    "#     print(target.size())\n",
    "#     target_mask = target > 0\n",
    "#     input_tensor_masked = input_tensor[target_mask]\n",
    "#     target_masked = target[target_mask]\n",
    "#     print(input_tensor_masked.size(), target_masked.size())\n",
    "\n",
    "    input_tensor = input_tensor.transpose(2,1).transpose(2,3).contiguous()\n",
    "# #     print(input_tensor,target.view(n,h,w,c))\n",
    "#     print(c)\n",
    "    input_tensor = input_tensor[target.view(n,h,w,1).repeat(1,1,1,c)>=0].view(-1,c)\n",
    "    target_mask = target >= 0\n",
    "    target = target[target_mask]\n",
    "#     print(input_tensor.size(), input_tensor)\n",
    "#     print(target.size(), target)\n",
    "    loss = F.cross_entropy(input_tensor, target, weight=weight, size_average=False)\n",
    "#     print(loss)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Downloads/y/envs/tm/lib/python3.6/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(35163.7812, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_image = torch.randn((1,3,224,224))*255\n",
    "# print(input_image)\n",
    "label = input_image[:,0,:,:]>0.5\n",
    "label = label.long()\n",
    "output=model(input_image)\n",
    "\n",
    "crossentropy_loss(output, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 224, 224])\n",
      "0 tensor(34265.8477, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "1 tensor(30528.4277, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "2 tensor(67677.6484, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "3 tensor(32483.7109, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "4 tensor(24791.6016, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "5 tensor(23256.0176, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "6 tensor(20329.7168, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "7 tensor(17884.5781, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "8 tensor(16936.2539, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "9 tensor(16223.1729, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "10 tensor(15625.4209, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "11 tensor(15185.3691, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "12 tensor(14665.1885, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "13 tensor(13989.7754, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "14 tensor(13280.1738, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "15 tensor(12560.2354, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "16 tensor(11863.2207, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "17 tensor(11187.6797, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "18 tensor(10512.0273, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "19 tensor(9835.0645, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "20 tensor(9184.7168, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "21 tensor(8582.7334, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "22 tensor(8021.4888, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "23 tensor(7498.2568, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "24 tensor(7034.7866, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "25 tensor(6650.0391, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "26 tensor(6320.2124, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "27 tensor(5998.2456, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "28 tensor(5689.0591, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "29 tensor(5436.3301, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "30 tensor(5233.3872, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "31 tensor(5030.6479, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "32 tensor(4807.0679, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "33 tensor(4585.9067, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "34 tensor(4400.5947, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "35 tensor(4251.4897, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "36 tensor(4107.6240, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "37 tensor(3963.1479, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "38 tensor(3838.2366, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "39 tensor(3732.1155, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "40 tensor(3621.1538, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "41 tensor(3510.2051, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "42 tensor(3417.8772, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "43 tensor(3329.6841, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "44 tensor(3235.3301, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "45 tensor(3154.8269, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "46 tensor(3088.0518, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "47 tensor(3017.8655, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "48 tensor(2947.6292, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "49 tensor(2885.5859, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "50 tensor(2825.0632, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "51 tensor(2768.7969, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "52 tensor(2716.7227, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "53 tensor(2662.3823, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "54 tensor(2614.4678, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "55 tensor(2570.4319, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "56 tensor(2523.6226, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "57 tensor(2482.6865, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "58 tensor(2443.7383, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "59 tensor(2403.7378, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "60 tensor(2367.8906, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "61 tensor(2331.3242, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "62 tensor(2296.2700, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "63 tensor(2264.7285, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "64 tensor(2232.3857, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "65 tensor(2202.0347, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "66 tensor(2172.7290, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "67 tensor(2144.0710, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "68 tensor(2116.5581, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "69 tensor(2089.3982, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "70 tensor(2063.3459, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "71 tensor(2038.5321, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "72 tensor(2014.3658, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "73 tensor(1990.2540, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "74 tensor(1967.1471, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "75 tensor(1944.4021, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "76 tensor(1923.0238, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "77 tensor(1901.6423, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "78 tensor(1880.9362, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "79 tensor(1860.5829, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "80 tensor(1840.7863, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "81 tensor(1821.7250, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 tensor(1803.2679, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "83 tensor(1785.0641, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "84 tensor(1767.2480, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "85 tensor(1749.8171, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "86 tensor(1732.8342, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "87 tensor(1716.5768, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "88 tensor(1700.2693, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "89 tensor(1684.5549, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "90 tensor(1668.9146, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "91 tensor(1653.8530, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "92 tensor(1639.2179, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "93 tensor(1624.5293, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "94 tensor(1610.2886, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "95 tensor(1596.4105, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "96 tensor(1582.7701, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "97 tensor(1569.3075, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "98 tensor(1556.2172, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "99 tensor(1543.5828, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "100 tensor(1531.2678, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "101 tensor(1520.1819, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "102 tensor(1514.8988, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "103 tensor(1541.1576, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "104 tensor(1701.4868, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "105 tensor(1997.8402, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "106 tensor(2409.1399, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "107 tensor(1887.7446, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "108 tensor(1659.1897, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "109 tensor(1843.8420, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "110 tensor(1603.9127, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "111 tensor(1668.5691, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "112 tensor(1566.2010, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "113 tensor(1613.5623, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "114 tensor(1503.9652, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "115 tensor(1579.8033, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "116 tensor(1458.9182, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "117 tensor(1531.0677, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "118 tensor(1448.2832, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "119 tensor(1473.6653, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "120 tensor(1441.2793, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "121 tensor(1429.5419, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "122 tensor(1420.5123, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "123 tensor(1409.9075, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "124 tensor(1385.9899, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "125 tensor(1392.5986, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "126 tensor(1359.4720, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "127 tensor(1368.7013, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "128 tensor(1340.1782, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "129 tensor(1341.6306, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "130 tensor(1324.1965, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "131 tensor(1317.5728, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "132 tensor(1308.0082, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "133 tensor(1296.0745, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "134 tensor(1290.7823, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "135 tensor(1277.9943, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "136 tensor(1272.5460, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "137 tensor(1261.6346, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "138 tensor(1255.1101, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "139 tensor(1245.0402, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "140 tensor(1239.5791, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "141 tensor(1228.5144, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "142 tensor(1226.0039, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "143 tensor(1212.2025, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "144 tensor(1211.7177, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "145 tensor(1199.4094, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "146 tensor(1195.5540, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "147 tensor(1188.0551, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "148 tensor(1181.0038, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "149 tensor(1174.0538, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "150 tensor(1169.9182, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "151 tensor(1160.6254, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "152 tensor(1156.6664, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "153 tensor(1149.9507, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "154 tensor(1144.2108, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "155 tensor(1136.9143, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "156 tensor(1132.9220, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "157 tensor(1126.2125, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "158 tensor(1121.0336, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "159 tensor(1114.3351, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "160 tensor(1109.8220, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "161 tensor(1104.4966, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "162 tensor(1099.2719, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "163 tensor(1093.2988, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164 tensor(1087.8806, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "165 tensor(1082.9126, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "166 tensor(1078.4508, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "167 tensor(1073.5222, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "168 tensor(1068.7584, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "169 tensor(1064.1161, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "170 tensor(1059.6991, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "171 tensor(1056.9243, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "172 tensor(1056.9471, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "173 tensor(1065.5975, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "174 tensor(1101.9019, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "175 tensor(1199.4591, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "176 tensor(1446.5734, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "177 tensor(1563.3867, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "178 tensor(1346.1694, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "179 tensor(1109.5430, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "180 tensor(1293.9611, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "181 tensor(1118.7632, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "182 tensor(1157.6880, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "183 tensor(1144.2833, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "184 tensor(1073.8160, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "185 tensor(1135.6250, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "186 tensor(1037.7084, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "187 tensor(1127.7390, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "188 tensor(1035.6720, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "189 tensor(1078.1289, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "190 tensor(1025.4595, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "191 tensor(1051.4417, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "192 tensor(1021.9526, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "193 tensor(1030.5582, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "194 tensor(1002.9077, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "195 tensor(1014.3377, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "196 tensor(1000.7707, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "197 tensor(995.2049, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "198 tensor(989.5079, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "199 tensor(979.7632, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "200 tensor(982.1501, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "201 tensor(972.3417, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "202 tensor(967.7793, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "203 tensor(959.6865, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "204 tensor(958.7095, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "205 tensor(951.7780, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "206 tensor(949.6980, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "207 tensor(942.5537, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "208 tensor(937.5546, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "209 tensor(935.4948, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "210 tensor(929.8973, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "211 tensor(927.8672, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "212 tensor(921.9265, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "213 tensor(919.5238, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "214 tensor(913.0016, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "215 tensor(911.1212, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "216 tensor(907.2995, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "217 tensor(903.6763, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "218 tensor(901.4995, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "219 tensor(897.7700, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "220 tensor(895.8831, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "221 tensor(892.2114, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "222 tensor(890.9722, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "223 tensor(890.7032, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "224 tensor(893.0101, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "225 tensor(902.4271, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "226 tensor(927.8364, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "227 tensor(989.3499, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "228 tensor(1135.9006, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "229 tensor(1373.2333, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "230 tensor(1601.0742, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "231 tensor(1318.1842, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "232 tensor(889.4437, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "233 tensor(1134.9717, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "234 tensor(1097.9801, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "235 tensor(896.8942, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "236 tensor(1073.6604, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "237 tensor(910.1603, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "238 tensor(980.2603, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "239 tensor(930.0873, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "240 tensor(931.4985, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "241 tensor(913.5333, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "242 tensor(920.0059, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "243 tensor(880.8600, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "244 tensor(913.5109, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "245 tensor(863.1286, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246 tensor(893.7197, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "247 tensor(858.3022, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "248 tensor(868.2557, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "249 tensor(855.5798, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "250 tensor(847.4069, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "251 tensor(849.8184, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "252 tensor(834.3759, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "253 tensor(838.5348, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "254 tensor(828.3619, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "255 tensor(824.5114, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "256 tensor(822.6156, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "257 tensor(813.0576, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "258 tensor(816.3904, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "259 tensor(805.1871, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "260 tensor(806.7501, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "261 tensor(800.0262, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "262 tensor(798.1519, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "263 tensor(793.7281, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "264 tensor(791.1389, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "265 tensor(786.2346, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "266 tensor(786.2726, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "267 tensor(778.6526, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "268 tensor(780.0119, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "269 tensor(773.3861, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "270 tensor(772.5789, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "271 tensor(769.2303, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "272 tensor(765.9545, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "273 tensor(763.4425, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "274 tensor(760.9733, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "275 tensor(757.3754, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "276 tensor(755.6683, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "277 tensor(752.6263, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "278 tensor(750.0252, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "279 tensor(747.4276, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "280 tensor(745.5793, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "281 tensor(741.7966, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "282 tensor(740.6597, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "283 tensor(737.6541, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "284 tensor(735.4727, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "285 tensor(733.7679, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "286 tensor(732.7114, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "287 tensor(733.5577, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "288 tensor(739.5590, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "289 tensor(761.7419, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "290 tensor(826.0817, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "291 tensor(1018.5204, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "292 tensor(1514.7140, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "293 tensor(2380.6167, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "294 tensor(2223.0398, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "295 tensor(851.4260, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "296 tensor(1484.8342, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "297 tensor(1221.1207, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "298 tensor(962.2625, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "299 tensor(1224.1608, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "300 tensor(865.1813, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "301 tensor(1092.4618, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "302 tensor(861.7798, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "303 tensor(980.0637, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "304 tensor(868.6957, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "305 tensor(898.7227, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "306 tensor(871.4865, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "307 tensor(835.9253, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "308 tensor(864.1626, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "309 tensor(805.1188, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "310 tensor(834.5704, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "311 tensor(793.2905, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "312 tensor(803.2241, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "313 tensor(786.7773, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "314 tensor(773.3265, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "315 tensor(779.7253, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "316 tensor(751.4717, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "317 tensor(769.9703, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "318 tensor(736.7886, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "319 tensor(756.4141, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "320 tensor(728.0212, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "321 tensor(741.0050, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "322 tensor(723.0638, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "323 tensor(724.4387, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "324 tensor(719.6054, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "325 tensor(710.2106, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "326 tensor(715.5047, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "327 tensor(699.8588, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328 tensor(707.5904, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "329 tensor(694.2781, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "330 tensor(697.6096, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "331 tensor(690.8198, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "332 tensor(687.9754, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "333 tensor(686.9012, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "334 tensor(680.4639, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "335 tensor(681.5935, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "336 tensor(675.1682, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "337 tensor(675.3313, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "338 tensor(670.8635, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "339 tensor(669.3643, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "340 tensor(666.3694, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "341 tensor(664.3008, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "342 tensor(661.5906, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "343 tensor(659.7551, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "344 tensor(656.8634, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "345 tensor(655.5168, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "346 tensor(652.1816, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "347 tensor(651.3899, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "348 tensor(647.7742, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "349 tensor(647.1541, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "350 tensor(643.7790, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "351 tensor(642.7905, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "352 tensor(640.0381, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "353 tensor(638.5062, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "354 tensor(636.2792, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "355 tensor(634.4558, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "356 tensor(632.5268, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "357 tensor(630.5412, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "358 tensor(628.8264, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "359 tensor(626.7589, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "360 tensor(625.1306, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "361 tensor(623.1303, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "362 tensor(621.4482, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "363 tensor(619.6099, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "364 tensor(617.8315, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "365 tensor(616.1134, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "366 tensor(614.3315, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "367 tensor(612.6329, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "368 tensor(610.9006, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "369 tensor(609.2134, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "370 tensor(607.5264, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "371 tensor(605.8326, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "372 tensor(604.2104, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "373 tensor(602.5128, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "374 tensor(600.9211, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "375 tensor(599.2764, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "376 tensor(597.6700, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "377 tensor(596.0784, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "378 tensor(594.4649, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "379 tensor(592.9257, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "380 tensor(591.3090, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "381 tensor(589.8011, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "382 tensor(588.2149, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "383 tensor(586.7173, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "384 tensor(585.1608, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "385 tensor(583.6656, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "386 tensor(582.1551, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "387 tensor(580.6588, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "388 tensor(579.1763, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "389 tensor(577.7018, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "390 tensor(576.2281, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "391 tensor(574.7831, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "392 tensor(573.3223, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "393 tensor(571.8937, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "394 tensor(570.4648, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "395 tensor(569.0336, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "396 tensor(567.6370, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "397 tensor(566.2167, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "398 tensor(564.8299, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "399 tensor(563.4391, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "400 tensor(562.0543, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "401 tensor(560.6844, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "402 tensor(559.3198, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "403 tensor(557.9587, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "404 tensor(556.6121, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "405 tensor(555.2686, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "406 tensor(553.9282, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "407 tensor(552.6015, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "408 tensor(551.2774, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "409 tensor(549.9627, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410 tensor(548.6523, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "411 tensor(547.3492, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "412 tensor(546.0530, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "413 tensor(544.7650, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "414 tensor(543.4839, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "415 tensor(542.2116, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "416 tensor(540.9538, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "417 tensor(539.7169, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "418 tensor(538.5327, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "419 tensor(537.4626, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "420 tensor(536.6981, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "421 tensor(536.7332, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "422 tensor(538.9388, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "423 tensor(547.2142, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "424 tensor(572.5048, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "425 tensor(646.9204, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "426 tensor(855.6064, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "427 tensor(1386.1864, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "428 tensor(2335.2903, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "429 tensor(2595.9077, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "430 tensor(883.2381, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "431 tensor(1145.2953, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "432 tensor(1400.8304, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "433 tensor(686.8179, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "434 tensor(1231.1064, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "435 tensor(666.6115, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "436 tensor(1049.7438, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "437 tensor(670.3614, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "438 tensor(931.1674, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "439 tensor(655.4382, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "440 tensor(842.0758, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "441 tensor(656.9643, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "442 tensor(753.9922, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "443 tensor(672.8551, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "444 tensor(671.3975, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "445 tensor(689.9952, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "446 tensor(613.0269, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "447 tensor(687.2541, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "448 tensor(589.3749, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "449 tensor(654.1138, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "450 tensor(596.3347, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "451 tensor(608.1614, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "452 tensor(608.4791, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "453 tensor(575.8403, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "454 tensor(605.0020, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "455 tensor(565.0206, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "456 tensor(586.5060, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "457 tensor(565.2764, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "458 tensor(566.7255, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "459 tensor(564.5162, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "460 tensor(554.2886, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "461 tensor(558.0652, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "462 tensor(547.1964, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "463 tensor(550.3137, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "464 tensor(542.4675, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "465 tensor(542.2051, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "466 tensor(538.5223, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "467 tensor(534.9010, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "468 tensor(534.5038, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "469 tensor(529.7163, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "470 tensor(529.2812, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "471 tensor(526.0490, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "472 tensor(524.0056, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "473 tensor(522.4424, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "474 tensor(519.7933, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "475 tensor(518.3362, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "476 tensor(516.4010, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "477 tensor(514.1044, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "478 tensor(513.3439, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "479 tensor(510.3232, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "480 tensor(509.9670, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "481 tensor(507.2768, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "482 tensor(506.1693, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "483 tensor(504.8641, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "484 tensor(502.3689, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "485 tensor(502.3397, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "486 tensor(499.1866, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "487 tensor(499.3639, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "488 tensor(496.6064, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "489 tensor(496.1884, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "490 tensor(494.2272, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "491 tensor(493.1807, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492 tensor(491.7773, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "493 tensor(490.4610, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "494 tensor(489.2342, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "495 tensor(487.9112, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "496 tensor(486.7084, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "497 tensor(485.4657, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "498 tensor(484.2604, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "499 tensor(483.0560, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "summary = SummaryWriter(\"runs/Plots\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "input_image = plt.imread(\"./index.png\")\n",
    "# print(input_image.shape)\n",
    "input_image = torch.FloatTensor(input_image).transpose(1,2).transpose(0,1)\n",
    "# print(input_image.size())\n",
    "# print(input_image)\n",
    "input_image = input_image.repeat(1,1,1,1)[:,:,:224,:224]\n",
    "label = input_image[:,0,:,:]>=0.5\n",
    "label = label.long()\n",
    "# print(label)\n",
    "# print(label*255)\n",
    "\n",
    "# input_image = torch.randn((1,3,224,224))*255\n",
    "\n",
    "\n",
    "\n",
    "print(label.size())\n",
    "summary.add_images(\"original_image\",input_image)\n",
    "summary.add_image(\"label_image\", label.float())\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(500):\n",
    "    optimizer.zero_grad()\n",
    "    # print(input_image)\n",
    "    \n",
    "    output=model(input_image)\n",
    "    loss = crossentropy_loss(output, label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(epoch,loss)\n",
    "    print(output.shape)\n",
    "    print(nn.Softmax2d()(output)[0,0].shape)\n",
    "#     print(output)\n",
    "    summary.add_scalar(\"Loss\",loss,epoch)\n",
    "    summary.add_image(\"output_images_region1\", nn.Softmax2d()(output)[0,0].view(1,224,224), epoch)\n",
    "    summary.add_image(\"output_images_region2\", nn.Softmax2d()(output)[0,1].view(1,224,224), epoch)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(imgdir):\n",
    "    input_image = plt.imread(imgdir)\n",
    "    input_image = torch.FloatTensor(input_image).transpose(1,2).transpose(0,1)\n",
    "    input_image = input_image.repeat(1,1,1,1)[:,:,:224*3,:224*3]\n",
    "    print(input_image.size())\n",
    "    output=model(input_image)\n",
    "    summary.add_image(\"test_image\", input_image[0,0])\n",
    "    summary.add_image(\"test_output_images_region1\", nn.Softmax2d()(output)[0,0].view(1,224*3,224*3))\n",
    "    summary.add_image(\"test_output_images_region2\", nn.Softmax2d()(output)[0,1].view(1,224*3,224*3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 672, 672])\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "size of input tensor and input format are different",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ba0b12b04c60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./index11.jpeg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-38b16e571d1a>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(imgdir)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_image\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_output_images_region1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmax2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test_output_images_region2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmax2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/y/envs/tm/lib/python3.6/site-packages/tensorboardX/writer.py\u001b[0m in \u001b[0;36madd_image\u001b[0;34m(self, tag, img_tensor, global_step, walltime, dataformats)\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mimg_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworkspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFetchBlob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         self.file_writer.add_summary(\n\u001b[0;32m--> 427\u001b[0;31m             image(tag, img_tensor, dataformats=dataformats), global_step, walltime)\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwalltime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataformats\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'NCHW'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/y/envs/tm/lib/python3.6/site-packages/tensorboardX/summary.py\u001b[0m in \u001b[0;36mimage\u001b[0;34m(tag, tensor, rescale, dataformats)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0mtag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_clean_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_HWC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataformats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m     \u001b[0;31m# Do not assume that user passes in values in [0, 255], use data type to detect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0mscale_factor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_calc_scale_factor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Downloads/y/envs/tm/lib/python3.6/site-packages/tensorboardX/utils.py\u001b[0m in \u001b[0;36mconvert_to_HWC\u001b[0;34m(tensor, input_format)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"You can not use the same dimension shordhand twice.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"size of input tensor and input format are different\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0minput_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: size of input tensor and input format are different"
     ]
    }
   ],
   "source": [
    "test(\"./index11.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TM",
   "language": "python",
   "name": "tm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
