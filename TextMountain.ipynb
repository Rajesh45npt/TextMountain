{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, models, transforms\n",
    "import os\n",
    "import copy\n",
    "from IPython.display import clear_output\n",
    "from torchsummary import summary\n",
    "from tensorboardX import SummaryWriter\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "ResNet = models.resnet50(pretrained=True)\n",
    "# for classifier in ResNet.children():\n",
    "#     print(classifier)\n",
    "#     input()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from torchsummary import summary\n",
    "summary(ResNet, (3,224,224))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from tensorboardX import SummaryWriter\n",
    "with SummaryWriter(\"runs/resnet\",comment=\"Model Resnet\") as w:\n",
    "    w.add_graph(ResNet, torch.zeros(1,3,224,224), False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Downloads/y/envs/tm/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.UpsamplingNearest2d is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n",
      "/home/raj/Downloads/y/envs/tm/lib/python3.6/site-packages/ipykernel_launcher.py:90: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "/home/raj/Downloads/y/envs/tm/lib/python3.6/site-packages/ipykernel_launcher.py:91: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "/home/raj/Downloads/y/envs/tm/lib/python3.6/site-packages/torch/nn/modules/upsampling.py:129: UserWarning: nn.UpsamplingBilinear2d is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.{} is deprecated. Use nn.functional.interpolate instead.\".format(self.name))\n",
      "/home/raj/Downloads/y/envs/tm/lib/python3.6/site-packages/torch/onnx/symbolic.py:131: UserWarning: ONNX export failed on upsample_bilinear2d because align_corners == True not supported\n",
      "  warnings.warn(\"ONNX export failed on \" + op + \" because \" + msg + \" not supported\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
      "             ReLU-81          [-1, 256, 28, 28]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
      "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-89         [-1, 1024, 14, 14]               0\n",
      "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
      "             ReLU-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
      "            ReLU-103          [-1, 256, 14, 14]               0\n",
      "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
      "            ReLU-106          [-1, 256, 14, 14]               0\n",
      "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-109         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
      "            ReLU-113          [-1, 256, 14, 14]               0\n",
      "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
      "            ReLU-116          [-1, 256, 14, 14]               0\n",
      "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-143          [-1, 512, 14, 14]               0\n",
      "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-146            [-1, 512, 7, 7]               0\n",
      "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-151           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-155            [-1, 512, 7, 7]               0\n",
      "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-158            [-1, 512, 7, 7]               0\n",
      "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-161           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-165            [-1, 512, 7, 7]               0\n",
      "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-168            [-1, 512, 7, 7]               0\n",
      "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-171           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-173            [-1, 256, 7, 7]         524,544\n",
      "          Conv2d-174            [-1, 128, 7, 7]         295,040\n",
      "          Conv2d-175            [-1, 128, 7, 7]         147,584\n",
      "UpsamplingNearest2d-176          [-1, 256, 14, 14]               0\n",
      "          Conv2d-177          [-1, 256, 14, 14]         262,400\n",
      "          Conv2d-178          [-1, 128, 14, 14]         295,040\n",
      "          Conv2d-179          [-1, 128, 14, 14]         147,584\n",
      "UpsamplingNearest2d-180          [-1, 256, 28, 28]               0\n",
      "          Conv2d-181          [-1, 256, 28, 28]         131,328\n",
      "          Conv2d-182          [-1, 128, 28, 28]         295,040\n",
      "          Conv2d-183          [-1, 128, 28, 28]         147,584\n",
      "UpsamplingNearest2d-184          [-1, 256, 56, 56]               0\n",
      "          Conv2d-185          [-1, 256, 56, 56]          65,792\n",
      "          Conv2d-186          [-1, 128, 56, 56]         295,040\n",
      "          Conv2d-187          [-1, 128, 56, 56]         147,584\n",
      "UpsamplingNearest2d-188          [-1, 128, 56, 56]               0\n",
      "UpsamplingNearest2d-189          [-1, 128, 56, 56]               0\n",
      "UpsamplingNearest2d-190          [-1, 128, 56, 56]               0\n",
      "          Conv2d-191          [-1, 512, 54, 54]       2,359,808\n",
      "     BatchNorm2d-192          [-1, 512, 54, 54]           1,024\n",
      "            ReLU-193          [-1, 512, 54, 54]               0\n",
      "          Conv2d-194            [-1, 2, 54, 54]           1,026\n",
      "================================================================\n",
      "Total params: 28,624,450\n",
      "Trainable params: 28,624,450\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 354.25\n",
      "Params size (MB): 109.19\n",
      "Estimated Total Size (MB): 464.02\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        resnet_layers = list(models.resnet50(pretrained=True).children())\n",
    "#         print(resnet_layers)\n",
    "        self.resnet_1 = nn.Sequential(*resnet_layers[:-5])\n",
    "        self.resnet_2 = nn.Sequential(*resnet_layers[-5])\n",
    "        self.resnet_3 = nn.Sequential(*resnet_layers[-4])\n",
    "        self.resnet_4 = nn.Sequential(*resnet_layers[-3])\n",
    "        \n",
    "        self.conv11_resnet_1 = nn.Conv2d(in_channels=256,out_channels=256, kernel_size=(1,1), stride=(1,1))\n",
    "        self.conv11_resnet_2 = nn.Conv2d(in_channels=512,out_channels=256, kernel_size=(1,1), stride=(1,1))\n",
    "        self.conv11_resnet_3 = nn.Conv2d(in_channels=1024,out_channels=256, kernel_size=(1,1), stride=(1,1))\n",
    "        self.conv11_resnet_4 = nn.Conv2d(in_channels=2048,out_channels=256, kernel_size=(1,1), stride=(1,1))\n",
    "        \n",
    "        self.scaling_1 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.scaling_2 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.scaling_3 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        \n",
    "        self.conv33_td1_1 = nn.Conv2d(in_channels=256, out_channels=128,kernel_size=(3,3),stride=(1,1), padding=(1,1))\n",
    "        self.conv33_td1_2 = nn.Conv2d(in_channels=128, out_channels=128,kernel_size=(3,3),stride=(1,1), padding=(1,1))\n",
    "        self.conv33_td2_1 = nn.Conv2d(in_channels=256, out_channels=128,kernel_size=(3,3),stride=(1,1), padding=(1,1))\n",
    "        self.conv33_td2_2 = nn.Conv2d(in_channels=128, out_channels=128,kernel_size=(3,3),stride=(1,1), padding=(1,1))\n",
    "        self.conv33_td3_1 = nn.Conv2d(in_channels=256, out_channels=128,kernel_size=(3,3),stride=(1,1), padding=(1,1))\n",
    "        self.conv33_td3_2 = nn.Conv2d(in_channels=128, out_channels=128,kernel_size=(3,3),stride=(1,1), padding=(1,1))\n",
    "        self.conv33_td4_1 = nn.Conv2d(in_channels=256, out_channels=128,kernel_size=(3,3),stride=(1,1), padding=(1,1))\n",
    "        self.conv33_td4_2 = nn.Conv2d(in_channels=128, out_channels=128,kernel_size=(3,3),stride=(1,1), padding=(1,1))\n",
    "        \n",
    "        self.scaling_P1 = nn.UpsamplingNearest2d(scale_factor=8)\n",
    "        self.scaling_P2 = nn.UpsamplingNearest2d(scale_factor=4)\n",
    "        self.scaling_P3 = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        \n",
    "        self.conv3_final = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=(3,3), stride=(1,1))\n",
    "        self.batchnorm_final = nn.BatchNorm2d(512)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.conv1_final = nn.Conv2d(in_channels=512, out_channels=2, kernel_size=(1,1), stride=(1,1))\n",
    "        \n",
    "        \n",
    "#         self.scaling = nn.ConvTranspose2d(in_channels=256, out_channels=256,kernel_size=(2,2), stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_bu1 = self.resnet_1(x)\n",
    "        x_bu2 = self.resnet_2(x_bu1)\n",
    "        x_bu3 = self.resnet_3(x_bu2)\n",
    "        x_bu4 = self.resnet_4(x_bu3)\n",
    "#         print(\"Bottom-up\")\n",
    "#         print(x_bu1.shape)\n",
    "#         print(x_bu2.shape)\n",
    "#         print(x_bu3.shape)\n",
    "#         print(x_bu4.shape)\n",
    "        \n",
    "        \n",
    "        x_td1 = self.conv11_resnet_4(x_bu4)\n",
    "        P_1 = self.conv33_td1_1(x_td1)\n",
    "        P_1 = self.conv33_td1_2(P_1)\n",
    "        \n",
    "        x_td2_1 = self.scaling_1(x_td1)\n",
    "        x_td2_2 = self.conv11_resnet_3(x_bu3)\n",
    "        x_td2 = x_td2_1+x_td2_2\n",
    "        P_2 = self.conv33_td2_1(x_td2)\n",
    "        P_2 = self.conv33_td2_2(P_2)\n",
    "        \n",
    "        x_td3_1 = self.scaling_2(x_td2)\n",
    "        x_td3_2 = self.conv11_resnet_2(x_bu2)\n",
    "        x_td3 = x_td3_1+x_td3_2\n",
    "        P_3 = self.conv33_td3_1(x_td3)\n",
    "        P_3 = self.conv33_td3_2(P_3)\n",
    "        \n",
    "        x_td4_1 = self.scaling_3(x_td3)\n",
    "        x_td4_2 = self.conv11_resnet_1(x_bu1)\n",
    "        x_td4 = x_td4_1+x_td4_2\n",
    "        P_4 = self.conv33_td4_1(x_td4)\n",
    "        P_4 = self.conv33_td4_2(P_4)\n",
    "        \n",
    "        \n",
    "        P_1 = self.scaling_P1(P_1)\n",
    "        P_2 = self.scaling_P2(P_2)\n",
    "        P_3 = self.scaling_P3(P_3)\n",
    "        \n",
    "        P_concat = torch.cat((P_1, P_2, P_3, P_4), dim=1)\n",
    "        F = P_concat\n",
    "#         print(\"P_concat\")\n",
    "#         print(P_concat.shape)\n",
    "        \n",
    "        F = self.conv3_final(F)\n",
    "        F = self.batchnorm_final(F)\n",
    "        F = self.activation(F)\n",
    "        \n",
    "        F = self.conv1_final(F)\n",
    "        F = nn.UpsamplingBilinear2d(size = (int(x.size()[-2]),\n",
    "                                          int(x.size()[-1])))(F)\n",
    "#         F = nn.Softmax2d()(F)\n",
    "#         print(\"Top-down\")\n",
    "#         print(x_td4.shape)\n",
    "#         print(x_td3.shape)\n",
    "#         print(x_td2.shape)\n",
    "#         print(x_td1.shape)\n",
    "        \n",
    "#         print(\"P\")\n",
    "#         print(P_1.shape)\n",
    "#         print(P_2.shape)\n",
    "#         print(P_3.shape)\n",
    "#         print(P_4.shape)\n",
    "#         print(P_concat.shape)\n",
    "        \n",
    "#         print(\"F\")\n",
    "#         print(x.shape)\n",
    "#         print(F.shape)\n",
    "        \n",
    "        \n",
    "        return F\n",
    "with SummaryWriter(\"runs/MyModel\") as w:\n",
    "    w.add_graph(MyModel(),torch.zeros(1,3,224,224), False)\n",
    "summary(MyModel(), (3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 224, 224])\n",
      "tensor(0.1044, grad_fn=<SelectBackward>) tensor(0.0045, grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = MyModel()\n",
    "out=model(torch.randn((2,3,224,224)))\n",
    "print(out.shape)\n",
    "print(out[1,0,1,1], out[1,1,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 224, 224])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossentropy_loss(input_tensor, target=None, weight=None ):\n",
    "    n,c,h,w = input_tensor.size()\n",
    "    \n",
    "    \n",
    "#     target = target.repeat(1,3,1,1)\n",
    "#     print(target.size())\n",
    "#     target_mask = target > 0\n",
    "#     input_tensor_masked = input_tensor[target_mask]\n",
    "#     target_masked = target[target_mask]\n",
    "#     print(input_tensor_masked.size(), target_masked.size())\n",
    "\n",
    "    input_tensor = input_tensor.transpose(2,1).transpose(2,3).contiguous()\n",
    "# #     print(input_tensor,target.view(n,h,w,c))\n",
    "#     print(c)\n",
    "    input_tensor = input_tensor[target.view(n,h,w,1).repeat(1,1,1,c)>=0].view(-1,c)\n",
    "    target_mask = target >= 0\n",
    "    target = target[target_mask]\n",
    "#     print(input_tensor.size(), input_tensor)\n",
    "#     print(target.size(), target)\n",
    "    loss = F.cross_entropy(input_tensor, target, weight=weight, size_average=False)\n",
    "#     print(loss)\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raj/Downloads/y/envs/tm/lib/python3.6/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(35375.0781, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_image = torch.randn((1,3,224,224))*255\n",
    "# print(input_image)\n",
    "label = input_image[:,0,:,:]>0.5\n",
    "label = label.long()\n",
    "output=model(input_image)\n",
    "\n",
    "crossentropy_loss(output, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(225, 225, 3)\n",
      "tensor([[[1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         ...,\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1],\n",
      "         [1, 1, 1,  ..., 1, 1, 1]]])\n",
      "torch.Size([1, 224, 224])\n",
      "0 tensor(35987.4844, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "1 tensor(30866.7207, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "2 tensor(71620.8203, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "3 tensor(54867.0273, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "4 tensor(26046.6387, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "5 tensor(21762.0469, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "6 tensor(19846.3477, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "7 tensor(18667.7363, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "8 tensor(17960.5996, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "9 tensor(17323.6641, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "10 tensor(16784.6523, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "11 tensor(16342.1104, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "12 tensor(15754.1094, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "13 tensor(14998.8936, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "14 tensor(14250.2324, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "15 tensor(13530.7500, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "16 tensor(12825.7041, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "17 tensor(12108.7021, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "18 tensor(11353.6074, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "19 tensor(10598.4619, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "20 tensor(9881.8369, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "21 tensor(9231.1973, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "22 tensor(8653.2998, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "23 tensor(8158.2422, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "24 tensor(7722.9316, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "25 tensor(7322.0859, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "26 tensor(6943.3877, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "27 tensor(6598.8066, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "28 tensor(6293.4946, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "29 tensor(6005.1543, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "30 tensor(5725.2871, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "31 tensor(5465.1538, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "32 tensor(5223.1675, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "33 tensor(4999.3843, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "34 tensor(4798.7363, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "35 tensor(4614.5986, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "36 tensor(4445.6899, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "37 tensor(4302.0610, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "38 tensor(4160.7476, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "39 tensor(4025.8020, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "40 tensor(3911.8201, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "41 tensor(3800.0500, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "42 tensor(3696.9062, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "43 tensor(3603.6189, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "44 tensor(3511.6892, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "45 tensor(3420.3701, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "46 tensor(3340.0601, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "47 tensor(3261.7407, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "48 tensor(3185.0059, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "49 tensor(3114.8521, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "50 tensor(3045.5413, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "51 tensor(2983.1611, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "52 tensor(2924.0396, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "53 tensor(2864.8247, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "54 tensor(2811.9763, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "55 tensor(2758.8896, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "56 tensor(2710.0454, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "57 tensor(2664.2561, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "58 tensor(2618.6294, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "59 tensor(2575.7498, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "60 tensor(2534.4990, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "61 tensor(2495.0471, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "62 tensor(2456.4214, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "63 tensor(2419.1221, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "64 tensor(2384.1619, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "65 tensor(2350.3733, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "66 tensor(2317.3440, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "67 tensor(2286.0212, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "68 tensor(2255.9155, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "69 tensor(2226.4524, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "70 tensor(2198.1914, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "71 tensor(2170.9751, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "72 tensor(2144.7366, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "73 tensor(2118.7261, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "74 tensor(2093.6238, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "75 tensor(2069.2810, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "76 tensor(2045.1906, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "77 tensor(2022.0392, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "78 tensor(1999.4205, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "79 tensor(1977.3411, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 tensor(1956.2225, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "81 tensor(1935.7028, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "82 tensor(1915.5758, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "83 tensor(1896.6155, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "84 tensor(1879.7042, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "85 tensor(1870.2745, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "86 tensor(1894.9774, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "87 tensor(2035.5662, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "88 tensor(2546.3892, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "89 tensor(2694.9570, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "90 tensor(2065.4954, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "91 tensor(2015.0176, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "92 tensor(2120.7656, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "93 tensor(1856.7059, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "94 tensor(1981.6345, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "95 tensor(1861.9340, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "96 tensor(1864.1022, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "97 tensor(1834.9526, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "98 tensor(1794.5493, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "99 tensor(1790.3195, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "100 tensor(1766.7720, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "101 tensor(1734.7289, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "102 tensor(1734.0210, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "103 tensor(1691.2975, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "104 tensor(1704.8098, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "105 tensor(1652.8306, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "106 tensor(1670.1617, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "107 tensor(1623.7820, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "108 tensor(1632.6095, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "109 tensor(1602.6387, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "110 tensor(1595.7893, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "111 tensor(1575.7889, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "112 tensor(1568.2520, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "113 tensor(1549.1492, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "114 tensor(1543.5419, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "115 tensor(1521.6781, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "116 tensor(1519.7118, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "117 tensor(1499.2052, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "118 tensor(1495.7083, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "119 tensor(1478.9384, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "120 tensor(1470.2086, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "121 tensor(1460.7968, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "122 tensor(1447.8932, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "123 tensor(1442.1189, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "124 tensor(1426.4862, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "125 tensor(1423.2863, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "126 tensor(1407.9739, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "127 tensor(1402.7853, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "128 tensor(1392.0103, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "129 tensor(1382.5978, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "130 tensor(1375.1108, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "131 tensor(1365.5717, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "132 tensor(1357.0485, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "133 tensor(1350.1160, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "134 tensor(1340.2273, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "135 tensor(1332.8329, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "136 tensor(1325.0736, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "137 tensor(1316.1508, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "138 tensor(1309.6770, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "139 tensor(1301.3632, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "140 tensor(1293.4977, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "141 tensor(1287.7299, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "142 tensor(1279.8137, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "143 tensor(1272.9485, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "144 tensor(1270.7842, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "145 tensor(1282.8927, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "146 tensor(1373.5681, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "147 tensor(1802.6820, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "148 tensor(2538.0156, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "149 tensor(2232.1348, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "150 tensor(1434.3005, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "151 tensor(1949.7236, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "152 tensor(1389.5161, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "153 tensor(1697.3148, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "154 tensor(1423.3140, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "155 tensor(1523.9132, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "156 tensor(1448.5326, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "157 tensor(1391.4084, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "158 tensor(1455.2946, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "159 tensor(1331.1399, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "160 tensor(1396.3486, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "161 tensor(1338.5740, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162 tensor(1317.4701, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "163 tensor(1333.6703, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "164 tensor(1278.5898, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "165 tensor(1295.7247, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "166 tensor(1269.6593, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "167 tensor(1254.9072, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "168 tensor(1253.2616, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "169 tensor(1231.3093, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "170 tensor(1228.5746, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "171 tensor(1215.0857, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "172 tensor(1206.7039, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "173 tensor(1197.5594, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "174 tensor(1184.3356, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "175 tensor(1185.8353, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "176 tensor(1164.9924, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "177 tensor(1166.6152, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "178 tensor(1156.4778, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "179 tensor(1144.0433, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "180 tensor(1147.3667, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "181 tensor(1129.3832, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "182 tensor(1131.4158, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "183 tensor(1120.4197, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "184 tensor(1114.3270, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "185 tensor(1112.0428, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "186 tensor(1099.2280, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "187 tensor(1101.6802, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "188 tensor(1088.3406, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "189 tensor(1088.4218, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "190 tensor(1080.3038, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "191 tensor(1074.6648, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "192 tensor(1072.0758, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "193 tensor(1063.1088, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "194 tensor(1062.1194, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "195 tensor(1053.5552, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "196 tensor(1051.7156, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "197 tensor(1044.6947, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "198 tensor(1041.4900, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "199 tensor(1035.8146, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "200 tensor(1032.0613, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "201 tensor(1026.7690, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "202 tensor(1022.9089, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "203 tensor(1017.8972, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "204 tensor(1014.0712, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "205 tensor(1009.1038, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "206 tensor(1005.4911, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "207 tensor(1000.5935, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "208 tensor(997.0733, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "209 tensor(992.3448, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "210 tensor(988.7366, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "211 tensor(984.2869, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "212 tensor(980.6603, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "213 tensor(976.4300, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "214 tensor(972.6807, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "215 tensor(968.7227, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "216 tensor(964.8906, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "217 tensor(961.0775, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "218 tensor(957.3052, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "219 tensor(953.5162, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "220 tensor(949.9612, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "221 tensor(946.0505, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "222 tensor(942.7134, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "223 tensor(938.8592, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "224 tensor(935.6673, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "225 tensor(932.3040, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "226 tensor(930.0050, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "227 tensor(930.2501, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "228 tensor(940.1602, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "229 tensor(987.5243, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "230 tensor(1170.5079, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "231 tensor(1696.2767, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "232 tensor(2276.1294, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "233 tensor(1925.7736, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "234 tensor(1096.4841, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "235 tensor(1680.0394, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "236 tensor(1108.9811, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "237 tensor(1373.8485, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "238 tensor(1124.0399, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "239 tensor(1181.1926, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "240 tensor(1160.5424, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "241 tensor(1028.9404, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "242 tensor(1162.6279, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "243 tensor(1011.6740, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244 tensor(1043.4880, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "245 tensor(1067.7036, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "246 tensor(970.9899, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "247 tensor(1019.9176, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "248 tensor(1007.6403, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "249 tensor(953.1216, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "250 tensor(978.3885, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "251 tensor(971.7954, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "252 tensor(932.6992, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "253 tensor(947.1423, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "254 tensor(948.4360, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "255 tensor(914.7028, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "256 tensor(922.1281, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "257 tensor(924.5359, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "258 tensor(899.3420, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "259 tensor(901.3985, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "260 tensor(905.0179, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "261 tensor(884.8271, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "262 tensor(885.0921, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "263 tensor(885.7273, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "264 tensor(872.7728, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "265 tensor(870.8279, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "266 tensor(869.5234, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "267 tensor(861.9822, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "268 tensor(856.6963, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "269 tensor(856.3443, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "270 tensor(849.9678, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "271 tensor(845.3901, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "272 tensor(843.0497, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "273 tensor(839.6617, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "274 tensor(833.8384, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "275 tensor(832.0115, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "276 tensor(828.5183, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "277 tensor(823.9086, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "278 tensor(821.2969, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "279 tensor(817.9862, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "280 tensor(814.3218, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "281 tensor(810.9703, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "282 tensor(808.2805, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "283 tensor(804.6252, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "284 tensor(801.3663, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "285 tensor(798.8917, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "286 tensor(795.2824, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "287 tensor(792.1783, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "288 tensor(789.8175, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "289 tensor(786.1863, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "290 tensor(783.4680, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "291 tensor(780.8922, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "292 tensor(777.5698, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "293 tensor(774.9850, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "294 tensor(772.2704, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "295 tensor(769.3079, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "296 tensor(766.7266, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "297 tensor(764.0731, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "298 tensor(761.2975, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "299 tensor(758.8742, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "300 tensor(756.1649, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "301 tensor(753.6759, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "302 tensor(751.2529, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "303 tensor(748.6872, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "304 tensor(746.3127, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "305 tensor(743.8551, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "306 tensor(741.5212, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "307 tensor(739.1133, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "308 tensor(736.8192, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "309 tensor(734.4616, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "310 tensor(732.1891, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "311 tensor(729.8973, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "312 tensor(727.6893, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "313 tensor(725.4183, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "314 tensor(723.2366, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "315 tensor(721.0504, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "316 tensor(718.8604, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "317 tensor(716.7256, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "318 tensor(714.5772, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "319 tensor(712.4857, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "320 tensor(710.3828, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "321 tensor(708.3212, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "322 tensor(706.3392, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "323 tensor(704.4261, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "324 tensor(702.8363, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "325 tensor(701.9819, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326 tensor(703.3615, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "327 tensor(711.3272, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "328 tensor(740.2618, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "329 tensor(836.7838, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "330 tensor(1144.3878, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "331 tensor(1752.4755, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "332 tensor(1572.6132, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "333 tensor(851.7982, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "334 tensor(961.2055, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "335 tensor(1097.1249, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "336 tensor(783.7916, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "337 tensor(973.4020, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "338 tensor(820.2039, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "339 tensor(865.0707, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "340 tensor(827.3240, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "341 tensor(804.2858, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "342 tensor(808.5332, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "343 tensor(776.0865, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "344 tensor(784.9954, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "345 tensor(752.4324, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "346 tensor(767.9827, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "347 tensor(735.2245, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "348 tensor(750.8365, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "349 tensor(723.4680, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "350 tensor(734.4942, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "351 tensor(714.2369, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "352 tensor(720.2381, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "353 tensor(707.9998, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "354 tensor(705.4761, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "355 tensor(701.3388, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "356 tensor(695.0288, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "357 tensor(694.4625, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "358 tensor(685.3748, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "359 tensor(688.0961, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "360 tensor(677.6575, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "361 tensor(680.5088, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "362 tensor(672.1004, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "363 tensor(673.2796, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "364 tensor(666.5381, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "365 tensor(666.8881, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "366 tensor(661.6395, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "367 tensor(660.9468, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "368 tensor(656.6998, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "369 tensor(655.3256, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "370 tensor(652.7509, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "371 tensor(649.6433, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "372 tensor(648.9823, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "373 tensor(644.5426, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "374 tensor(644.9724, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "375 tensor(640.2511, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "376 tensor(640.6086, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "377 tensor(636.4805, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "378 tensor(636.3292, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "379 tensor(632.5992, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "380 tensor(632.5774, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "381 tensor(628.6214, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "382 tensor(628.7242, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "383 tensor(625.2603, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "384 tensor(624.5544, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "385 tensor(622.1393, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "386 tensor(620.6129, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "387 tensor(618.9134, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "388 tensor(616.9282, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "389 tensor(615.7410, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "390 tensor(613.3463, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "391 tensor(612.5161, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "392 tensor(610.1021, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "393 tensor(609.0427, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "394 tensor(607.1747, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "395 tensor(605.5848, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "396 tensor(604.1797, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "397 tensor(602.3284, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "398 tensor(601.1158, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "399 tensor(599.2301, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "400 tensor(597.9656, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "401 tensor(596.3410, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "402 tensor(594.7687, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "403 tensor(593.4214, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "404 tensor(591.7928, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "405 tensor(590.3923, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "406 tensor(588.9123, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "407 tensor(587.3903, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408 tensor(586.0585, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "409 tensor(584.4776, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "410 tensor(583.1069, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "411 tensor(581.7003, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "412 tensor(580.2009, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "413 tensor(578.8616, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "414 tensor(577.4213, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "415 tensor(576.0070, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "416 tensor(574.6786, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "417 tensor(573.2162, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "418 tensor(571.8634, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "419 tensor(570.5128, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "420 tensor(569.0983, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "421 tensor(567.7665, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "422 tensor(566.4039, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "423 tensor(565.0167, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "424 tensor(563.7012, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "425 tensor(562.3587, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "426 tensor(561.0005, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "427 tensor(559.6939, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "428 tensor(558.3635, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "429 tensor(557.0330, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "430 tensor(555.7297, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "431 tensor(554.4223, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "432 tensor(553.1094, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "433 tensor(551.8145, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "434 tensor(550.5255, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "435 tensor(549.2273, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "436 tensor(547.9448, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "437 tensor(546.6735, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "438 tensor(545.4005, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "439 tensor(544.1326, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "440 tensor(542.8759, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "441 tensor(541.6284, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "442 tensor(540.3798, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "443 tensor(539.1446, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "444 tensor(537.9209, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "445 tensor(536.7183, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "446 tensor(535.5505, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "447 tensor(534.4785, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "448 tensor(533.6695, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "449 tensor(533.5737, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "450 tensor(535.5140, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "451 tensor(543.5239, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "452 tensor(569.5632, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "453 tensor(650.3748, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "454 tensor(889.6135, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "455 tensor(1481.0446, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "456 tensor(2253.6365, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "457 tensor(1988.4136, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "458 tensor(879.9757, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "459 tensor(1110.0562, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "460 tensor(990.2681, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "461 tensor(896.6221, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "462 tensor(867.0646, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "463 tensor(835.3865, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "464 tensor(803.1772, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "465 tensor(752.7687, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "466 tensor(759.6593, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "467 tensor(722.2329, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "468 tensor(694.0547, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "469 tensor(712.3591, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "470 tensor(640.3356, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "471 tensor(700.6174, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "472 tensor(610.3146, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "473 tensor(673.1890, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "474 tensor(603.2515, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "475 tensor(632.9312, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "476 tensor(608.7595, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "477 tensor(594.4922, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "478 tensor(612.9974, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "479 tensor(567.8106, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "480 tensor(606.0043, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "481 tensor(558.3871, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "482 tensor(585.7778, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "483 tensor(561.7085, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "484 tensor(561.1172, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "485 tensor(567.1113, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "486 tensor(541.8723, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "487 tensor(564.2505, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "488 tensor(535.2575, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "489 tensor(553.2380, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490 tensor(534.1915, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "491 tensor(541.2946, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "492 tensor(534.1514, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "493 tensor(530.7710, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "494 tensor(532.7747, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "495 tensor(523.7718, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "496 tensor(528.9750, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "497 tensor(519.0779, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "498 tensor(524.1051, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n",
      "499 tensor(516.2751, grad_fn=<NllLossBackward>)\n",
      "torch.Size([1, 2, 224, 224])\n",
      "torch.Size([224, 224])\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "summary = SummaryWriter(\"runs/Plots\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "input_image = plt.imread(\"./index.png\")\n",
    "# print(input_image.shape)\n",
    "input_image = torch.FloatTensor(input_image).transpose(1,2).transpose(0,1)\n",
    "# print(input_image.size())\n",
    "# print(input_image)\n",
    "input_image = input_image.repeat(1,1,1,1)[:,:,:224,:224]\n",
    "label = input_image[:,0,:,:]>=0.5\n",
    "label = label.long()\n",
    "# print(label)\n",
    "# print(label*255)\n",
    "\n",
    "# input_image = torch.randn((1,3,224,224))*255\n",
    "\n",
    "\n",
    "\n",
    "print(label.size())\n",
    "summary.add_images(\"original_image\",input_image)\n",
    "summary.add_image(\"label_image\", label.float())\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(500):\n",
    "    optimizer.zero_grad()\n",
    "    # print(input_image)\n",
    "    \n",
    "    output=model(input_image)\n",
    "    loss = crossentropy_loss(output, label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(epoch,loss)\n",
    "    print(output.shape)\n",
    "    print(nn.Softmax2d()(output)[0,0].shape)\n",
    "#     print(output)\n",
    "    summary.add_scalar(\"Loss\",loss,epoch)\n",
    "    summary.add_image(\"output_images_region1\", nn.Softmax2d()(output)[0,0].view(1,224,224), epoch)\n",
    "    summary.add_image(\"output_images_region2\", nn.Softmax2d()(output)[0,1].view(1,224,224), epoch)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(imgdir):\n",
    "    input_image = plt.imread(imgdir)\n",
    "    input_image = torch.FloatTensor(input_image).transpose(1,2).transpose(0,1)\n",
    "    input_image = input_image.repeat(1,1,1,1)[:,:,:224*3,:224*3]\n",
    "    print(input_image.size())\n",
    "    output=model(input_image)\n",
    "    summary.add_image(\"test_image\", input_image[0])\n",
    "    summary.add_image(\"test_output_images_region1\", nn.Softmax2d()(output)[0,0].view(1,224*3,224*3))\n",
    "    summary.add_image(\"test_output_images_region2\", nn.Softmax2d()(output)[0,1].view(1,224*3,224*3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 672, 672])\n"
     ]
    }
   ],
   "source": [
    "test(\"./index11.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TM",
   "language": "python",
   "name": "tm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
